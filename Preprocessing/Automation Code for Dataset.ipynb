{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "046b8ab3",
   "metadata": {},
   "source": [
    "## How to use this code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e68a249",
   "metadata": {},
   "source": [
    "#### To see each experiment in EEG\n",
    "eeg_process = EEGProcessor(r\"C:\\Users\\ballj\\OneDrive\\바탕 화면\\EEG_jm.csv\", time_interval = 20, remove_time_in_group = 15) <br>\n",
    "#### To get total experiment for each person\n",
    "eeg_process = EEGProcessor(r\"C:\\Users\\ballj\\OneDrive\\바탕 화면\\EEG_jm.csv\", time_interval = 20, remove_time_in_group = 15) <br>\n",
    "data = pd.read_csv(r\"C:\\Users\\ballj\\OneDrive\\바탕 화면\\EEG_jm.csv\") <br>\n",
    "위의 해당 파트에서 경로 변경, time_interval, remove_time_in_group 변경하면서 사용하면 됨. <br>\n",
    "time_interval : 그룹화 할 초 단위 (ex. 20초)<br>\n",
    "remove_time_in_group : 그룹 내에서 오류값 처리의 기준이 되는 초 (ex. 15초). 예를 들어, 15초 이상의 값이 존재하지만 20초까지는 안 되는 그룹의 경우 (ex. 16초) 는 이 값을 살려 해당 구간을 임의로 늘려서 16초간의 평균값을 20초 구간의 대표값으로 가져가도록 한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad459765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class EEGProcessor:\n",
    "    #time_interval : Fitbit과 통일할 초 (ex. 20초) \n",
    "    #remove_time_in_group : time_interval 그룹 내에서 오류값 처리의 threshold로 사용할 기준 초\n",
    "    def __init__(self, file_path, time_interval, remove_time_in_group):\n",
    "        self.time_interval = time_interval\n",
    "        self.remove_time_in_group = remove_time_in_group\n",
    "        self.time_interval_str = f'{time_interval}S'\n",
    "        self.EEG_report = pd.read_csv(file_path)\n",
    "\n",
    "    #리스트 값을 row로 변환하는 함수\n",
    "    def parse_raw_data(self, dataframe, col_name):\n",
    "        col_str = dataframe.iloc[0][col_name]\n",
    "        col_str = col_str.strip('[]')\n",
    "        col_list = [float(val) for val in col_str.split(',')]  # 쉼표로 구분된 값을 리스트로 변환\n",
    "        col_data = pd.DataFrame({col_name: col_list})\n",
    "        return col_data\n",
    "\n",
    "    #측정 시간 출력 함수\n",
    "    def time_difference(self, dataframe, start_time_col, finish_time_col):\n",
    "        start_time = datetime.strptime(dataframe.iloc[0][start_time_col], '%Y-%m-%d %H:%M:%S')\n",
    "        finish_time = datetime.strptime(dataframe.iloc[0][finish_time_col], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # 두 datetime 객체 간의 차이 계산\n",
    "        time_difference = (finish_time - start_time).total_seconds()\n",
    "        return time_difference\n",
    "    \n",
    "    #실험 초기 인식 오류 기간 비교 후, 삭제할 부분 삭제\n",
    "    def count_initial_same_values(self, series):\n",
    "        initial_value = series.iloc[0]\n",
    "        count = 0\n",
    "        for value in series:\n",
    "            if value == initial_value:\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "        return count\n",
    "    \n",
    "    # 앞, 뒤로 0,20,40초 단위로 잘리지 않는 값들에 대한 처리 (15초 이상이면 살리기)\n",
    "    def process_start_time_trash_sec(self, dt):\n",
    "        # 입력된 시간에서 분은 1 더하고 초는 버림\n",
    "        rounded_time = dt + timedelta(minutes=1) - timedelta(seconds=dt.second)\n",
    "        time_difference = (rounded_time - dt).total_seconds()\n",
    "\n",
    "        # 20초로 나눈 나머지 계산 ex. 12\n",
    "        remainder = time_difference % float(self.time_interval)\n",
    "\n",
    "        # 나머지가 15초 미만의 데이터는 버리고, 15초 이상의 데이터는 버리는 것 없이 그대로 사용하기\n",
    "        if self.remove_time_in_group <= remainder:\n",
    "            return False\n",
    "        else:\n",
    "        # ex. 2023-10-15 00:21:04 -> remainder : 16 (False)\n",
    "        # ex. 2023-10-15 00:21:15 -> remainder : 5\n",
    "            return remainder\n",
    "\n",
    "    def process_finish_time_trash_sec(self, dt):\n",
    "        # 입력된 시간에서 초는 버림\n",
    "        rounded_time = dt - timedelta(seconds=dt.second)\n",
    "        time_difference = (dt - rounded_time).total_seconds()\n",
    "\n",
    "        # 20초로 나눈 나머지 계산\n",
    "        remainder = time_difference % float(self.time_interval)\n",
    "\n",
    "        if self.remove_time_in_group <= remainder:\n",
    "            return False\n",
    "\n",
    "        else:\n",
    "        #ex. 2023-10-15 00:40:46 -> remainder : 6\n",
    "        #ex. 2023-10-15 00:40:56 -> remainder : 16 (False)\n",
    "            return remainder\n",
    "\n",
    "    def nearest_time_rounding(self, dt):\n",
    "        # 주어진 시간의 초를 추출\n",
    "        seconds = dt.second\n",
    "        # 0, 20, 40초 중 가장 가까운 값을 찾기 위한 리스트\n",
    "        time_points = [i for i in range(0,60, self.time_interval)]\n",
    "        # 가장 가까운 초 값 찾기\n",
    "        nearest = min(time_points, key=lambda x: abs(x - seconds))\n",
    "        # 찾은 초 값으로 시간 변경\n",
    "        # 만약 nearest가 40이고 seconds가 55보다 크다면, 분을 1 더해주고 초를 0으로 설정\n",
    "        if nearest == time_points[-1] and seconds >= (time_points[-1] + self.remove_time_in_group):\n",
    "            rounded_time = dt.replace(second=0, microsecond=0) + timedelta(minutes=1)\n",
    "        else:\n",
    "            rounded_time = dt.replace(second=nearest, microsecond=0)\n",
    "\n",
    "        return rounded_time\n",
    "\n",
    "    # 실험 종료 시간 맞춰주기\n",
    "    # 더 늦게 끝나는 데이터프레임을 일찍 끝나는 데이터프레임에 맞춰야 함\n",
    "    def align_end_time(self, df1, df2):\n",
    "        if df1.index[-1] > df2.index[-1]:\n",
    "            df1 = df1[df1.index <= df2.index[-1]]\n",
    "\n",
    "        elif df1.index[-1] < df2.index[-1]:\n",
    "            df2 = df2[df2.index <= df1.index[-1]]\n",
    "\n",
    "        else: \n",
    "            pass # 두 데이터프레임의 종료 시간이 동일한 경우\n",
    "\n",
    "        return df1, df2\n",
    "\n",
    "    # start time 가공 -> i : 0 , finish time 가공 -> i : -1\n",
    "    # start time 가공 -> process_start_time_trash_sec 함수 , finish time 가공 -> process_finish_time_trash_sec 함수\n",
    "    def adjust_time_index(self, i, df, func):\n",
    "        remainder = func(df.index[i])\n",
    "        #finish 부분에서 00초, 20초, 40초로 끝나면 가공된 마지막 row는 한 개의 데이터로 이루어지기 때문에 1초를 빼서 59, 19, 39초에서 마무리하고자\n",
    "        one_sec = timedelta(seconds=1)\n",
    "\n",
    "        if remainder == False:\n",
    "            # time을 가장 가까운 0, 20, 40초 중 하나로 변경\n",
    "            if i == 0 :\n",
    "                time = self.nearest_time_rounding(df.index[i])\n",
    "                new_index = df.index.tolist()\n",
    "                new_index[i] = time\n",
    "                df.index = new_index\n",
    "            else:\n",
    "                time = self.nearest_time_rounding(df.index[i]) - one_sec\n",
    "                new_index = df.index.tolist()\n",
    "                new_index[i] = time\n",
    "                df.index = new_index\n",
    "\n",
    "        else:\n",
    "            cutting_time = timedelta(seconds=remainder)        \n",
    "            # remainder가 15초 미만이면 버리고 그 이후부터 시작\n",
    "            if i == 0:\n",
    "                df = df[df.index >= df.index[i] + cutting_time]\n",
    "            # remainder가 15초 미만이면 버리고 그 이전 0,20,40초 중으로 마무리\n",
    "            else:\n",
    "                df = df[df.index <= df.index[-1] - cutting_time - one_sec]\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def check_invalid_values(self, group):\n",
    "        # brain wave에서 연속 0 차이값을 가지는 시간 구간 계산\n",
    "        alpha_invalid_series = group['α_wave_raw_data'].diff().eq(0)\n",
    "        alpha_invalid_timestamps = group.index[alpha_invalid_series].tolist()\n",
    "\n",
    "        # attention_raw_data에서 0 값을 가지는 시간 구간 계산\n",
    "        attention_invalid_series = group['attention_raw_data'] == 0\n",
    "        attention_invalid_timestamps = group.index[attention_invalid_series].tolist()\n",
    "\n",
    "        # 연속 0 차이값 또는 0 값을 가지는 시간 구간의 길이가 15초 이상인지 확인\n",
    "        def has_long_invalid_duration(invalid_timestamps):\n",
    "            if not invalid_timestamps:\n",
    "                return False\n",
    "            for i in range(1, len(invalid_timestamps)):\n",
    "                if (invalid_timestamps[i] - invalid_timestamps[i-1]).seconds > self.remove_time_in_group:\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        alpha_invalid = has_long_invalid_duration(alpha_invalid_timestamps)\n",
    "        attention_invalid = has_long_invalid_duration(attention_invalid_timestamps)\n",
    "\n",
    "        if alpha_invalid or attention_invalid:\n",
    "            return pd.Series([np.nan] * group.shape[1], index=group.columns)\n",
    "\n",
    "        else:\n",
    "            # 오류 값을 제외하고 평균 계산\n",
    "            valid_conditions = (\n",
    "                (group['α_wave_raw_data'].diff() != 0) & \n",
    "                (group['β_wave_raw_data'].diff() != 0) & \n",
    "                (group['θ_wave_raw_data'].diff() != 0) & \n",
    "                (group['δ_wave_raw_data'].diff() != 0) & \n",
    "                (group['γ_wave_raw_data'].diff() != 0) & \n",
    "                (group['attention_raw_data'] != 0)\n",
    "            )\n",
    "            return group[valid_conditions].mean()\n",
    "        \n",
    "    def check_invalid_values_other(self, group):\n",
    "        # hr에서 0 값을 가지는 시간 구간 계산\n",
    "        hr_invalid_series = group['hr_raw_data'] == 0\n",
    "        hr_invalid_timestamps = group.index[hr_invalid_series].tolist()\n",
    "\n",
    "        # 연속 0 차이값 또는 0 값을 가지는 시간 구간의 길이가 15초 이상인지 확인\n",
    "        def has_long_invalid_duration(invalid_timestamps):\n",
    "            if not invalid_timestamps:\n",
    "                return False\n",
    "            for i in range(1, len(invalid_timestamps)):\n",
    "                if (invalid_timestamps[i] - invalid_timestamps[i-1]).seconds > self.remove_time_in_group:\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        hr_invalid = has_long_invalid_duration(hr_invalid_timestamps)\n",
    "\n",
    "        if hr_invalid:\n",
    "            return pd.Series([np.nan] * group.shape[1], index=group.columns)\n",
    "\n",
    "        else:\n",
    "            # 오류 값을 제외하고 평균 계산\n",
    "            group = group[(group['hr_raw_data'] != 0)]\n",
    "            return group.mean()\n",
    "    \n",
    "    def process_data(self, experiment_id):\n",
    "        if experiment_id not in self.EEG_report.index:\n",
    "            return None\n",
    "\n",
    "        # 모든 실험들 for문으로 돌리고 하나의 데이터프레임으로 저장되어야 함.\n",
    "        EEG_report_sample = self.EEG_report.loc[[experiment_id],:]\n",
    "\n",
    "        #한 column당 하나의 dataframe\n",
    "        cols = ['α_wave_raw_data', 'β_wave_raw_data', 'θ_wave_raw_data', 'δ_wave_raw_data', 'γ_wave_raw_data', 'attention_raw_data', 'hrv_raw_data', 'hr_raw_data', 'coherence_flag_raw_data']\n",
    "        parsed_dfs = [self.parse_raw_data(EEG_report_sample, col) for col in cols]\n",
    "\n",
    "        #interval second 계산\n",
    "        interval_sec = self.time_difference(EEG_report_sample, 'meditation_start_time', 'meditation_finish_time') / len(parsed_dfs[0])\n",
    "        interval_sec_other = self.time_difference(EEG_report_sample, 'meditation_start_time', 'meditation_finish_time') / len(parsed_dfs[6])\n",
    "\n",
    "        #병합된 dataframe 생성\n",
    "        merged_df = parsed_dfs[0].join(parsed_dfs[1:6])\n",
    "        merged_df_other = parsed_dfs[6].join(parsed_dfs[7:])\n",
    "\n",
    "        #실험 시작 시간\n",
    "        start_time = datetime.strptime(EEG_report_sample.iloc[0]['meditation_start_time'], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        #실험 feature 별 interval sec 이용하여 실험 시간 time index로 데이터프레임 변환 (2가지)\n",
    "        interval_sec, interval_sec_other = timedelta(seconds=round(interval_sec,2)), timedelta(seconds=round(interval_sec_other,2))\n",
    "        merged_df['time'] = [start_time + i * interval_sec for i in range(len(merged_df))]\n",
    "        merged_df_other['time'] = [start_time + i * interval_sec_other for i in range(len(merged_df_other))]\n",
    "        merged_df, merged_df_other = merged_df.set_index('time'), merged_df_other.set_index('time')\n",
    "        \n",
    "        #실험 초기 인식 오류 기간 비교용\n",
    "        counts = [self.count_initial_same_values(merged_df[col]) for col in cols[:6]] + [self.count_initial_same_values(merged_df_other['hr_raw_data'])]\n",
    "        \n",
    "        #interval_sec 단위 float로 변경하여 비교\n",
    "        initial_error_times = [counts[i] * interval_sec.total_seconds() if i != 6 else counts[i] * interval_sec_other.total_seconds() for i in range(7)]\n",
    "        \n",
    "        # feature 별 초기 오류 시간 비교 후, 가장 오류 시간이 긴 것에 맞춰 initial error time 설정\n",
    "        initial_error_time = timedelta(seconds=max(initial_error_times))\n",
    "\n",
    "        # 초기 인식 오류 제거한 실험 data 시작 시간\n",
    "        real_start_time = start_time + initial_error_time\n",
    "        merged_df, merged_df_other = merged_df[merged_df.index > real_start_time], merged_df_other[merged_df_other.index > real_start_time]\n",
    "\n",
    "        # 데이터프레임 인덱스를 초 단위로 반올림\n",
    "        merged_df.index, merged_df_other.index = merged_df.index.round('S'), merged_df_other.index.round('S')\n",
    "\n",
    "        # 실험 종료 시간 맞춰주기\n",
    "        merged_df, merged_df_other = self.align_end_time(merged_df, merged_df_other)\n",
    "\n",
    "#         # 더 늦게 끝나는 데이터프레임을 일찍 끝나는 데이터프레임에 맞춰야 함.\n",
    "#         if merged_df.index[-1] > merged_df_other.index[-1]:\n",
    "#             merged_df = merged_df[merged_df.index <= merged_df_other.index[-1]]\n",
    "\n",
    "#         elif merged_df.index[-1] < merged_df_other.index[-1] :\n",
    "#             merged_df_other = merged_df_other[merged_df_other.index <= merged_df.index[-1]]\n",
    "            \n",
    "#         else:\n",
    "#             True\n",
    "\n",
    "        # start time 가공 -> i : 0 , finish time 가공 -> i : -1\n",
    "        # start time 가공 -> process_start_time_trash_sec 함수 , finish time 가공 -> process_finish_time_trash_sec 함수\n",
    "        merged_df = self.adjust_time_index(0, merged_df, self.process_start_time_trash_sec)\n",
    "        merged_df_other = self.adjust_time_index(0, merged_df_other, self.process_start_time_trash_sec)\n",
    "        merged_df = self.adjust_time_index(-1, merged_df, self.process_finish_time_trash_sec)\n",
    "        merged_df_other = self.adjust_time_index(-1, merged_df_other, self.process_finish_time_trash_sec)\n",
    "\n",
    "        # 20초 단위로 그룹화 (인덱스가 datetime 형태이므로 floor 사용)\n",
    "        grouped = merged_df.groupby(merged_df.index.floor(self.time_interval_str))\n",
    "        grouped_other = merged_df_other.groupby(merged_df_other.index.floor(self.time_interval_str))\n",
    "\n",
    "        result = grouped.apply(self.check_invalid_values)\n",
    "        result_other = grouped_other.apply(self.check_invalid_values_other)\n",
    "\n",
    "        # β/θ SP ratio를 포함한 최종 EEG 데이터셋\n",
    "        EEG_data_per_time_interval = result.merge(result_other, left_index=True, right_index=True)\n",
    "        EEG_data_per_time_interval['β/θ SP'] = EEG_data_per_time_interval['β_wave_raw_data'] / EEG_data_per_time_interval['θ_wave_raw_data']\n",
    "        \n",
    "        return EEG_data_per_time_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110c3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_process = EEGProcessor(r\"C:\\Users\\ballj\\OneDrive\\바탕 화면\\EEG_jm.csv\", time_interval = 20, remove_time_in_group = 15)\n",
    "# eeg_process.process_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19a1002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>α_wave_raw_data</th>\n",
       "      <th>β_wave_raw_data</th>\n",
       "      <th>θ_wave_raw_data</th>\n",
       "      <th>δ_wave_raw_data</th>\n",
       "      <th>γ_wave_raw_data</th>\n",
       "      <th>attention_raw_data</th>\n",
       "      <th>hrv_raw_data</th>\n",
       "      <th>hr_raw_data</th>\n",
       "      <th>coherence_flag_raw_data</th>\n",
       "      <th>β/θ SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-10-17 16:13:00</th>\n",
       "      <td>94.063528</td>\n",
       "      <td>99.213975</td>\n",
       "      <td>93.593869</td>\n",
       "      <td>84.868628</td>\n",
       "      <td>90.974541</td>\n",
       "      <td>69.156250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.275862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.060048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-17 16:13:20</th>\n",
       "      <td>94.835756</td>\n",
       "      <td>99.067247</td>\n",
       "      <td>95.416897</td>\n",
       "      <td>88.063403</td>\n",
       "      <td>91.330237</td>\n",
       "      <td>64.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.275862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.038257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-17 16:13:40</th>\n",
       "      <td>93.567144</td>\n",
       "      <td>99.964944</td>\n",
       "      <td>94.096141</td>\n",
       "      <td>86.123425</td>\n",
       "      <td>92.908906</td>\n",
       "      <td>66.906250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.928571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.062370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-17 16:14:00</th>\n",
       "      <td>92.150706</td>\n",
       "      <td>101.219152</td>\n",
       "      <td>90.821216</td>\n",
       "      <td>83.494384</td>\n",
       "      <td>93.286394</td>\n",
       "      <td>75.032258</td>\n",
       "      <td>19.103448</td>\n",
       "      <td>60.793103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.114488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-17 16:14:20</th>\n",
       "      <td>90.833428</td>\n",
       "      <td>100.648262</td>\n",
       "      <td>88.791894</td>\n",
       "      <td>80.487381</td>\n",
       "      <td>92.247284</td>\n",
       "      <td>86.406250</td>\n",
       "      <td>33.785714</td>\n",
       "      <td>59.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.133530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-13 14:55:40</th>\n",
       "      <td>97.990398</td>\n",
       "      <td>99.141016</td>\n",
       "      <td>89.786491</td>\n",
       "      <td>80.571006</td>\n",
       "      <td>88.462028</td>\n",
       "      <td>67.328125</td>\n",
       "      <td>39.107143</td>\n",
       "      <td>91.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.104186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-13 14:56:00</th>\n",
       "      <td>98.738189</td>\n",
       "      <td>99.106112</td>\n",
       "      <td>91.051269</td>\n",
       "      <td>81.310068</td>\n",
       "      <td>92.582797</td>\n",
       "      <td>62.784615</td>\n",
       "      <td>38.928571</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.088465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-13 14:56:20</th>\n",
       "      <td>97.644569</td>\n",
       "      <td>97.781563</td>\n",
       "      <td>89.892325</td>\n",
       "      <td>79.747017</td>\n",
       "      <td>91.389403</td>\n",
       "      <td>66.734375</td>\n",
       "      <td>18.035714</td>\n",
       "      <td>87.821429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.087763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-13 14:56:40</th>\n",
       "      <td>98.487597</td>\n",
       "      <td>96.751565</td>\n",
       "      <td>89.677660</td>\n",
       "      <td>79.865295</td>\n",
       "      <td>92.926508</td>\n",
       "      <td>60.646154</td>\n",
       "      <td>18.428571</td>\n",
       "      <td>83.928571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.078881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-13 14:57:00</th>\n",
       "      <td>97.869603</td>\n",
       "      <td>95.632556</td>\n",
       "      <td>89.570787</td>\n",
       "      <td>79.829875</td>\n",
       "      <td>96.678716</td>\n",
       "      <td>62.515625</td>\n",
       "      <td>44.035714</td>\n",
       "      <td>73.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.067676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>931 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     α_wave_raw_data  β_wave_raw_data  θ_wave_raw_data  \\\n",
       "2023-10-17 16:13:00        94.063528        99.213975        93.593869   \n",
       "2023-10-17 16:13:20        94.835756        99.067247        95.416897   \n",
       "2023-10-17 16:13:40        93.567144        99.964944        94.096141   \n",
       "2023-10-17 16:14:00        92.150706       101.219152        90.821216   \n",
       "2023-10-17 16:14:20        90.833428       100.648262        88.791894   \n",
       "...                              ...              ...              ...   \n",
       "2023-10-13 14:55:40        97.990398        99.141016        89.786491   \n",
       "2023-10-13 14:56:00        98.738189        99.106112        91.051269   \n",
       "2023-10-13 14:56:20        97.644569        97.781563        89.892325   \n",
       "2023-10-13 14:56:40        98.487597        96.751565        89.677660   \n",
       "2023-10-13 14:57:00        97.869603        95.632556        89.570787   \n",
       "\n",
       "                     δ_wave_raw_data  γ_wave_raw_data  attention_raw_data  \\\n",
       "2023-10-17 16:13:00        84.868628        90.974541           69.156250   \n",
       "2023-10-17 16:13:20        88.063403        91.330237           64.750000   \n",
       "2023-10-17 16:13:40        86.123425        92.908906           66.906250   \n",
       "2023-10-17 16:14:00        83.494384        93.286394           75.032258   \n",
       "2023-10-17 16:14:20        80.487381        92.247284           86.406250   \n",
       "...                              ...              ...                 ...   \n",
       "2023-10-13 14:55:40        80.571006        88.462028           67.328125   \n",
       "2023-10-13 14:56:00        81.310068        92.582797           62.784615   \n",
       "2023-10-13 14:56:20        79.747017        91.389403           66.734375   \n",
       "2023-10-13 14:56:40        79.865295        92.926508           60.646154   \n",
       "2023-10-13 14:57:00        79.829875        96.678716           62.515625   \n",
       "\n",
       "                     hrv_raw_data  hr_raw_data  coherence_flag_raw_data  \\\n",
       "2023-10-17 16:13:00      0.000000    61.275862                      0.0   \n",
       "2023-10-17 16:13:20      0.000000    63.275862                      0.0   \n",
       "2023-10-17 16:13:40      0.000000    64.928571                      0.0   \n",
       "2023-10-17 16:14:00     19.103448    60.793103                      0.0   \n",
       "2023-10-17 16:14:20     33.785714    59.500000                      0.0   \n",
       "...                           ...          ...                      ...   \n",
       "2023-10-13 14:55:40     39.107143    91.714286                      0.0   \n",
       "2023-10-13 14:56:00     38.928571    91.000000                      0.0   \n",
       "2023-10-13 14:56:20     18.035714    87.821429                      0.0   \n",
       "2023-10-13 14:56:40     18.428571    83.928571                      0.0   \n",
       "2023-10-13 14:57:00     44.035714    73.428571                      0.0   \n",
       "\n",
       "                       β/θ SP  \n",
       "2023-10-17 16:13:00  1.060048  \n",
       "2023-10-17 16:13:20  1.038257  \n",
       "2023-10-17 16:13:40  1.062370  \n",
       "2023-10-17 16:14:00  1.114488  \n",
       "2023-10-17 16:14:20  1.133530  \n",
       "...                       ...  \n",
       "2023-10-13 14:55:40  1.104186  \n",
       "2023-10-13 14:56:00  1.088465  \n",
       "2023-10-13 14:56:20  1.087763  \n",
       "2023-10-13 14:56:40  1.078881  \n",
       "2023-10-13 14:57:00  1.067676  \n",
       "\n",
       "[931 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eeg_process_extended = EEGProcessorExtended(r\"C:\\Users\\ballj\\OneDrive\\바탕 화면\\EEG_jm.csv\", time_interval=20, remove_time_in_group=15)\n",
    "eeg_process = EEGProcessor(r\"C:\\Users\\ballj\\OneDrive\\바탕 화면\\EEG_jm.csv\", time_interval = 20, remove_time_in_group = 16)\n",
    "data = pd.read_csv(r\"C:\\Users\\ballj\\OneDrive\\바탕 화면\\EEG_jm.csv\")\n",
    "result_dfs = []\n",
    "\n",
    "for exp_id in range(3, len(data)):\n",
    "    processed_data = eeg_process.process_data(exp_id)\n",
    "    if processed_data is not None:\n",
    "        result_dfs.append(processed_data)\n",
    "        \n",
    "if result_dfs:\n",
    "    combined_df = pd.concat(result_dfs)\n",
    "    \n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df.to_csv(r\"C:\\Users\\ballj\\OneDrive\\바탕 화면\\EEG_jm_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccfa2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
